# MLOps Plant Disease Classification System

A production-ready MLOps system for classifying plant diseases (Healthy, Powdery, Rust) using Convolutional Neural Networks (CNNs). This project transforms a research notebook into a scalable, reproducible, and automated machine learning pipeline.

## ğŸ— Architecture

The system follows MLOps best practices with the following components:

1.  **Data Management**: DVC for dataset versioning and lineage.
2.  **Experiment Tracking**: MLflow for logging parameters, metrics, and artifacts.
3.  **Model Development**: Modular TensorFlow/Keras implementation of VGGNet, AlexNet, ResNet, and Custom CNN.
4.  **CI/CT Pipeline**: GitHub Actions for automated testing and continuous training.
5.  **Deployment**: FastAPI application containerized with Docker and deployed on Kubernetes.
6.  **Monitoring**: Prometheus metrics and Evidently AI for data drift detection.
7.  **Orchestration**: Apache Airflow for automated retraining pipelines.

## ğŸ“‚ Project Structure

```
PlantDiseases_CNN_Classification/
â”œâ”€â”€ src/                    # Source code
â”‚   â”œâ”€â”€ data/              # Data loading & augmentation (DVC integrated)
â”‚   â”œâ”€â”€ models/            # Model architectures (VGG, AlexNet, ResNet)
â”‚   â”œâ”€â”€ config/            # Configuration management
â”‚   â”œâ”€â”€ tracking/          # MLflow tracking utilities
â”‚   â”œâ”€â”€ utils/             # Visualization & helpers
â”‚   â”œâ”€â”€ train.py           # Main training script
â”‚   â””â”€â”€ tune.py            # Hyperparameter tuning script
â”œâ”€â”€ serve/                 # Model serving
â”‚   â”œâ”€â”€ app.py             # FastAPI application
â”‚   â””â”€â”€ Dockerfile         # Container definition
â”œâ”€â”€ deploy/                # Deployment configurations
â”‚   â””â”€â”€ kubernetes/        # K8s manifests (Deployment, Service, Ingress)
â”œâ”€â”€ monitoring/            # Observability
â”‚   â””â”€â”€ data_drift_detector.py # Evidently AI drift detection
â”œâ”€â”€ pipelines/             # Orchestration
â”‚   â””â”€â”€ retraining_pipeline.py # Airflow DAGs
â”œâ”€â”€ tests/                 # Unit & integration tests
â”œâ”€â”€ configs/               # YAML experiment configs
â”œâ”€â”€ .github/workflows/     # CI/CT pipelines
â””â”€â”€ requirements.txt       # Project dependencies
```

## ğŸš€ Quick Start

### Prerequisites
- Python 3.9+
- Docker & Kubernetes (optional for local dev)
- Git

### Installation

1.  **Clone the repository**:
    ```bash
    git clone <repository-url>
    cd PlantDiseases_CNN_Classification
    ```

2.  **Install dependencies**:
    ```bash
    pip install -r requirements.txt
    ```

3.  **Initialize DVC** (if starting fresh):
    ```bash
    dvc init
    # Configure remote storage (e.g., Azure Blob / S3)
    # dvc remote add -d storage s3://my-bucket/data
    ```

### Training a Model

Run the training pipeline with default configuration:

```bash
python src/train.py
```

To use a specific model architecture:

```bash
python src/train.py --model vggnet --epochs 20
```

### Running the API

Start the FastAPI server locally:

```bash
uvicorn serve.app:app --reload
```

Access the API documentation at `http://localhost:8000/docs`.

## ğŸ“Š MLOps Workflows

### Experiment Tracking
Launch the MLflow UI to view experiments:
```bash
mlflow ui
```

### Hyperparameter Tuning
Run automated grid search:
```bash
python src/tune.py --epochs 5
```

### Deployment
Build and deploy to Kubernetes:
```bash
docker build -t plant-disease-classifier:latest -f serve/Dockerfile .
kubectl apply -f deploy/kubernetes/
```

## ğŸ“ˆ Monitoring

- **Metrics**: Prometheus metrics available at `/metrics`
- **Drift Detection**: Run `python monitoring/data_drift_detector.py` to generate reports

## ğŸ¤ Contributing
1. Fork the repository
2. Create a feature branch
3. Commit changes
4. Push to the branch
5. Open a Pull Request

## ğŸ“„ License
[MIT License](LICENSE)
